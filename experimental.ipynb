{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_and_validate_hierarchical\n",
    "\n",
    "train_csv = \"/mnt/Data/hackathon/final_train.csv\"\n",
    "val_csv = \"/mnt/Data/hackathon/final_valid.csv\"\n",
    "train_and_validate_hierarchical(train_csv, val_csv, epochs=100, batch_size=8, train_sweeps=1, val_sweeps=8, save_path='checkpoints/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer import infer_test\n",
    "\n",
    "# Call it directly\n",
    "infer_test(\n",
    "    test_csv='/mnt/Data/hackathon/final_test.csv',\n",
    "    model_path='checkpoints/best_model.pth',\n",
    "    n_sweeps_test=8,\n",
    "    output_csv='outputs/test_predictions.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b3946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from evaluate_metrics import compute_metrics\n",
    "\n",
    "compute_metrics(\n",
    "    pred_csv=\"outputs/test_predictions.csv\",\n",
    "    gt_csv=\"/mnt/Data/hackathon/final_valid.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def compute_metrics_by_trimester(pred_csv, gt_csv):\n",
    "    # Load data\n",
    "    pred_df = pd.read_csv(pred_csv)\n",
    "    gt_df = pd.read_csv(gt_csv)\n",
    "\n",
    "    # Ensure columns exist\n",
    "    if 'study_id' not in pred_df.columns or 'ga' not in pred_df.columns:\n",
    "        raise ValueError(\"Prediction CSV must contain 'study_id' and 'ga' columns.\")\n",
    "    if 'study_id' not in gt_df.columns or 'ga' not in gt_df.columns:\n",
    "        raise ValueError(\"Ground truth CSV must contain 'study_id' and 'ga' columns.\")\n",
    "\n",
    "    # Merge on study_id\n",
    "    merged = pd.merge(gt_df, pred_df, on='study_id', suffixes=('_true', '_pred'))\n",
    "    if merged.empty:\n",
    "        raise ValueError(\"No matching study_id values found between CSVs.\")\n",
    "\n",
    "    y_true = merged['ga_true']\n",
    "    y_pred = merged['ga_pred']\n",
    "\n",
    "    # Determine trimester thresholds (based on ground truth)\n",
    "    max_ga = y_true.max()\n",
    "    min_ga = y_true.min()\n",
    "    step = (max_ga - min_ga) / 3\n",
    "\n",
    "    trimester_bins = [min_ga, min_ga + step, min_ga + 2*step, max_ga]\n",
    "    trimester_labels = ['Trimester 1', 'Trimester 2', 'Trimester 3']\n",
    "\n",
    "    merged['trimester'] = pd.cut(y_true, bins=trimester_bins, labels=trimester_labels, include_lowest=True)\n",
    "\n",
    "    # Store results\n",
    "    results = []\n",
    "\n",
    "    for trimester in trimester_labels:\n",
    "        df_t = merged[merged['trimester'] == trimester]\n",
    "        if df_t.empty:\n",
    "            continue\n",
    "\n",
    "        y_t_true = df_t['ga_true'].values\n",
    "        y_t_pred = df_t['ga_pred'].values\n",
    "\n",
    "        mae = mean_absolute_error(y_t_true, y_t_pred)\n",
    "        mse = mean_squared_error(y_t_true, y_t_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_t_true, y_t_pred)\n",
    "        corr, _ = pearsonr(y_t_true, y_t_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"Trimester\": trimester,\n",
    "            \"Samples\": len(y_t_true),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"RÂ²\": r2,\n",
    "            \"Corr\": corr\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nðŸ“Š Metrics by Trimester\")\n",
    "    print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "    # Overall metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    print(\"\\nðŸ“ˆ Overall Metrics\")\n",
    "    print(\"---------------------------\")\n",
    "    print(f\"MAE   : {mae:.4f}\")\n",
    "    print(f\"MSE   : {mse:.4f}\")\n",
    "    print(f\"RMSE  : {rmse:.4f}\")\n",
    "    print(f\"RÂ²    : {r2:.4f}\")\n",
    "    print(f\"Corr  : {corr:.4f}\")\n",
    "    print(\"---------------------------\")\n",
    "    print(f\"Samples evaluated: {len(y_true)}\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimester_results = compute_metrics_by_trimester(\n",
    "    pred_csv=\"outputs/test_predictions.csv\",\n",
    "    gt_csv=\"/mnt/Data/hackathon/final_valid.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def compute_metrics_by_site(pred_csv, gt_csv):\n",
    "    # Load data\n",
    "    pred_df = pd.read_csv(pred_csv)\n",
    "    gt_df = pd.read_csv(gt_csv)\n",
    "\n",
    "    # Ensure columns exist\n",
    "    if 'study_id' not in pred_df.columns or 'ga' not in pred_df.columns:\n",
    "        raise ValueError(\"Prediction CSV must contain 'study_id' and 'ga' columns.\")\n",
    "    if 'study_id' not in gt_df.columns or 'ga' not in gt_df.columns:\n",
    "        raise ValueError(\"Ground truth CSV must contain 'study_id' and 'ga' columns.\")\n",
    "    if 'site' not in gt_df.columns:\n",
    "        raise ValueError(\"Ground truth CSV must contain a 'site' column for site-based evaluation.\")\n",
    "\n",
    "    # Merge predictions with ground truth\n",
    "    merged = pd.merge(gt_df, pred_df, on='study_id', suffixes=('_true', '_pred'))\n",
    "    if merged.empty:\n",
    "        raise ValueError(\"No matching study_id values found between CSVs.\")\n",
    "\n",
    "    # Extract arrays\n",
    "    y_true = merged['ga_true']\n",
    "    y_pred = merged['ga_pred']\n",
    "\n",
    "    # Compute metrics per site\n",
    "    site_results = []\n",
    "    for site, df_site in merged.groupby('site'):\n",
    "        y_s_true = df_site['ga_true'].values\n",
    "        y_s_pred = df_site['ga_pred'].values\n",
    "\n",
    "        mae = mean_absolute_error(y_s_true, y_s_pred)\n",
    "        mse = mean_squared_error(y_s_true, y_s_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_s_true, y_s_pred)\n",
    "        corr, _ = pearsonr(y_s_true, y_s_pred)\n",
    "\n",
    "        site_results.append({\n",
    "            \"Site\": site,\n",
    "            \"Samples\": len(y_s_true),\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"RÂ²\": r2,\n",
    "            \"Corr\": corr\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(site_results)\n",
    "\n",
    "    print(\"\\nðŸ“Š Metrics by Site\")\n",
    "    print(results_df.round(4).to_string(index=False))\n",
    "\n",
    "    # Compute overall metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    corr, _ = pearsonr(y_true, y_pred)\n",
    "\n",
    "    print(\"\\nðŸ“ˆ Overall Metrics\")\n",
    "    print(\"---------------------------\")\n",
    "    print(f\"MAE   : {mae:.4f}\")\n",
    "    print(f\"MSE   : {mse:.4f}\")\n",
    "    print(f\"RMSE  : {rmse:.4f}\")\n",
    "    print(f\"RÂ²    : {r2:.4f}\")\n",
    "    print(f\"Corr  : {corr:.4f}\")\n",
    "    print(\"---------------------------\")\n",
    "    print(f\"Samples evaluated: {len(y_true)}\")\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f13ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_results = compute_metrics_by_site(\n",
    "    pred_csv=\"outputs/test_predictions.csv\",\n",
    "    gt_csv=\"/mnt/Data/hackathon/final_valid.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "tensorboard --logdir=logs --port=6006\n",
    "\n",
    "ssh -L 6006:localhost:6006 team-ua@113.199.208.74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bb2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer import predict_ga\n",
    "\n",
    "model_path = \"checkpoints/best_model.pth\"\n",
    "test_csv = \"path/to/test.csv\"\n",
    "predictions = predict_ga(model_path, test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model\n",
    "\n",
    "best_mae, best_loss = train_model(\n",
    "    model_type='resnet18',\n",
    "    train_csv=\"/mnt/Data/hackathon/final_train.csv\",\n",
    "    val_csv=\"/mnt/Data/hackathon/final_valid.csv\",\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    reduced_dim=128,\n",
    "    fine_tune_backbone=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf91fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_model\n",
    "\n",
    "best_mae, best_loss = train_model(\n",
    "    model_type='convnext_tiny',\n",
    "    train_csv=\"/mnt/Data/hackathon/final_train.csv\",\n",
    "    val_csv=\"/mnt/Data/hackathon/final_valid.csv\",\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    reduced_dim=384,\n",
    "    fine_tune_backbone=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f5f5f-a5f6-4681-b50e-8a7a536238ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also call it programmatically\n",
    "from train import train_model\n",
    "\n",
    "# Train ResNet50\n",
    "best_mae, best_loss = train_model(\n",
    "    model_type='convnext_tiny',\n",
    "    train_csv=\"/mnt/Data/hackathon/final_train.csv\",\n",
    "    val_csv=\"/mnt/Data/hackathon/final_valid.csv\",\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    reduced_dim=256,\n",
    "    fine_tune_backbone=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8865367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sequential hierarchical model training...\n",
      "============================================================\n",
      "\n",
      "Training Model 1/3: resnet18\n",
      "   Architecture: hierarchical\n",
      "   Batch size: 8\n",
      "   Learning rate: 0.0001\n",
      "   Reduced dim: 128\n",
      "   Train sweeps: 2\n",
      "----------------------------------------\n",
      "Using device: cuda\n",
      "Training hierarchical_resnet18 model...\n",
      "Training with 2 sweep(s) per study\n",
      "Loading datasets...\n",
      "Train samples: 395\n",
      "Val samples: 50\n",
      "Train batches: 50\n",
      "Val batches: 7\n",
      "Creating hierarchical_resnet18 model...\n",
      "Total parameters: 12,360,385\n",
      "Trainable parameters: 12,360,385\n",
      "\n",
      "============================================================\n",
      "Starting training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50:\n",
      "  Train Loss: 150.0873 | Train MAE: 150.0873\n",
      "  Val Loss:   163.1494 | Val MAE:   163.1494\n",
      "  Learning Rate: 1.00e-04\n",
      "âœ… Saved new best model (Val MAE: 163.1494) to checkpoints_hierarchical/best_model_hierarchical_resnet18.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             \r"
     ]
    }
   ],
   "source": [
    "# train_sequential.py\n",
    "import time\n",
    "from train import train_model\n",
    "\n",
    "# List of models to train in hierarchical mode\n",
    "models_to_train = [\n",
    "    {\n",
    "        'model_type': 'resnet18',\n",
    "        'architecture': 'hierarchical',\n",
    "        'train_sweeps': 2,\n",
    "        'batch_size': 8,\n",
    "        'learning_rate': 1e-4,\n",
    "        'reduced_dim': 128,\n",
    "        'num_heads': 4,\n",
    "        'save_dir': 'checkpoints_hierarchical',\n",
    "        'experiment_name': 'hierarchical_resnet18'\n",
    "    },\n",
    "    {\n",
    "        'model_type': 'resnet50',\n",
    "        'architecture': 'hierarchical',\n",
    "        'train_sweeps': 2,\n",
    "        'batch_size': 4,\n",
    "        'learning_rate': 1e-4,\n",
    "        'reduced_dim': 256,\n",
    "        'num_heads': 4,\n",
    "        'save_dir': 'checkpoints_hierarchical',\n",
    "        'experiment_name': 'hierarchical_resnet50'\n",
    "    },\n",
    "    {\n",
    "        'model_type': 'convnext_tiny',\n",
    "        'architecture': 'hierarchical',\n",
    "        'train_sweeps': 2,\n",
    "        'batch_size': 8,\n",
    "        'learning_rate': 3e-5,\n",
    "        'reduced_dim': 384,\n",
    "        'num_heads': 4,\n",
    "        'save_dir': 'checkpoints_hierarchical',\n",
    "        'experiment_name': 'hierarchical_convnext'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Starting sequential hierarchical model training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, config in enumerate(models_to_train):\n",
    "    print(f\"\\nTraining Model {i+1}/{len(models_to_train)}: {config['model_type']}\")\n",
    "    print(f\"   Architecture: {config['architecture']}\")\n",
    "    print(f\"   Batch size: {config['batch_size']}\")\n",
    "    print(f\"   Learning rate: {config['learning_rate']}\")\n",
    "    print(f\"   Reduced dim: {config['reduced_dim']}\")\n",
    "    print(f\"   Train sweeps: {config['train_sweeps']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    try:\n",
    "        best_mae, best_loss = train_model(\n",
    "            model_type=config['model_type'],\n",
    "            architecture=config['architecture'],\n",
    "            train_csv=\"/mnt/Data/hackathon/final_train.csv\",\n",
    "            val_csv=\"/mnt/Data/hackathon/final_valid.csv\",\n",
    "            epochs=50,\n",
    "            batch_size=config['batch_size'],\n",
    "            train_sweeps=config['train_sweeps'],\n",
    "            n_sweeps_val=8,\n",
    "            learning_rate=config['learning_rate'],\n",
    "            reduced_dim=config['reduced_dim'],\n",
    "            num_heads=config['num_heads'],\n",
    "            fine_tune_backbone=True,\n",
    "            pretrained=True,\n",
    "            save_dir=config['save_dir']\n",
    "        )\n",
    "        \n",
    "        print(f\"{config['model_type']} completed!\")\n",
    "        print(f\"   Best MAE: {best_mae:.4f}\")\n",
    "        print(f\"   Best Loss: {best_loss:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{config['model_type']} failed: {e}\")\n",
    "    \n",
    "    # Wait between models (optional)\n",
    "    if i < len(models_to_train) - 1:\n",
    "        print(\"\\nWaiting 5 seconds before next model...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"All hierarchical models training completed!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ga_uganda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
